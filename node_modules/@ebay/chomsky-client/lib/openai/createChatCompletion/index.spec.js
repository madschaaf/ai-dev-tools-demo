'use strict';
const { assert } = require('chai');
const { openai, MODELS } = require('../../../');
const AppContext = require('@ebay/app-context-ebay');
const ebayFetch = require('@ebay/ebay-fetch');
AppContext.appName = 'usvbff';

jest.mock("@ebay/ebay-fetch", () => ({
  fetch: jest
    .fn()
    .mockImplementation(jest.requireActual("@ebay/ebay-fetch").fetch),
}));

describe('openai', () => {

    beforeEach(() => {
      ebayFetch.fetch.mockClear();
    });

    describe('openai.createChatCompletion', () => {
        it('should be a function', () => {
            assert.equal(typeof openai.createChatCompletion, 'function');
        });
        
        it('should create a chat completion request', (done) => {
            openai.createChatCompletion({
                model: MODELS.OPENAI.CHAT.AZURE_CHAT_COMPLETIONS_GPT_4_1_MINI_2025_04_14_SANDBOX,
                max_tokens: 10,
                messages: [
                    { role: 'system', content: 'You are a math bot. Give the answer only.' },
                    { role: 'user', content: '1+1' }
                ]
            }).then(res => {
                assert.hasAnyKeys(res, [
                    'id',
                    'object',
                    'created',
                    'model',
                    'choices',
                    'prompt_filter_results',
                    'usage'
                ]);

                done();
            }).catch(done);
        }, 10000);

        it.only('should create a chat completion request for reasoning model', (done) => {
            openai.createChatCompletion({
                model: MODELS.OPENAI.CHAT.AZURE_CHAT_COMPLETIONS_O3_MINI_2025_01_31_SANDBOX,
                max_completion_tokens: 100,
                reasoning_effort: "low",
                messages: [
                    { role: 'user', content: 'tell me a 400 word story' }
                ]
            }).then(res => {
                assert.hasAnyKeys(res, [
                    'id',
                    'object',
                    'created',
                    'model',
                    'choices',
                    'prompt_filter_results',
                    'usage'
                ]);

                assert(res.usage.completion_tokens <= 100);

                done();
            }).catch(done);
        }, 10000);

        it('should create a chat completion request with tracingEntityId and tracingEntityType parameters', async () => {
            const createChatCompletionRequest = {
                model:
                MODELS.OPENAI.CHAT.AZURE_CHAT_COMPLETIONS_GPT_4_1_MINI_2025_04_14_SANDBOX,
                max_tokens: 1,
                messages: [{ role: "user", content: "hello" }],
                tracingEntityId: "test-entity-id",
                tracingEntityType: "test-entity-type",
            };
    
            await openai.createChatCompletion(createChatCompletionRequest);

            assert.strictEqual(ebayFetch.fetch.mock.calls[0][2].headers["X-EBAY-TRACING-ENTITY-ID"], "test-entity-id");
            assert.strictEqual(ebayFetch.fetch.mock.calls[0][2].headers["X-EBAY-TRACING-ENTITY-TYPE"], "test-entity-type");
        });

        it('should create a chat completion request with streaming response', async () => {
            const response = await openai.createChatCompletion({
                model: MODELS.OPENAI.CHAT.AZURE_CHAT_COMPLETIONS_GPT_4_1_MINI_2025_04_14_SANDBOX,
                max_tokens: 10,
                messages: [
                    { role: 'user', content: 'Tell a joke' }
                ],
                stream: true
            });

            const { createParser } = await require('eventsource-parser');

            const chunks = [];
            const parser = createParser((event) => {
                if (event.type === 'event') {
                    const data = event.data;
                    if (data === '[DONE]') {
                        return;
                    }

                    try {
                        const json = JSON.parse(data);
                        chunks.push(json);
                    } catch (e) {
                        throw new Error(`Failed to parse JSON: ${data}`);
                    }
                }
            });

            for await (const chunk of response) {
                parser.feed(String(chunk));
            }

            const text = chunks.map(chunk => chunk.choices[0]?.delta.content || '').join('');
            assert.ok(text.length > 10);
        }, 10000);

        // it('should create a chat completion request with functions', (done) => {
        //     openai.createChatCompletion({
        //         model: MODELS.OPENAI.CHAT.AZURE_CHAT_COMPLETIONS_GPT4_0613,
        //         max_tokens: 1,
        //         messages: [{ "role": "user", "content": "What's the weather like in Boston?" }],
        //         functions: [
        //             {
        //                 "name": "get_current_weather",
        //                 "description": "Get the current weather in a given location",
        //                 "parameters": {
        //                     "type": "object",
        //                     "properties": {
        //                         "location": {
        //                             "type": "string",
        //                             "description": "The city and state, e.g. San Francisco, CA",
        //                         },
        //                         "unit": { "type": "string", "enum": ["celsius", "fahrenheit"] },
        //                     },
        //                     "required": ["location"],
        //                 },
        //             }
        //         ],
        //         function_call: "auto"
        //     }).then(res => {
        //         assert.hasAllKeys(res, [
        //             'id',
        //             'object',
        //             'created',
        //             'model',
        //             'choices',
        //             'usage'
        //         ]);

        //         done();
        //     }).catch(done);
        // });

        it('should create a chat completion request with tools', async () => {
            const res = await openai.createChatCompletion({
                model: MODELS.OPENAI.CHAT.AZURE_CHAT_COMPLETIONS_GPT_4_1_MINI_2025_04_14_SANDBOX,
                max_tokens: 100,
                messages: [{ "role": "user", "content": "What's the weather like in Boston?" }],
                tools: [
                    {
                        "type": "function",
                        "function": {
                            "name": "get_current_weather",
                            "description": "Get the current weather in a given location",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "location": {
                                        "type": "string",
                                        "description": "The city and state, e.g. San Francisco, CA",
                                    },
                                    "unit": { "type": "string", "enum": ["celsius", "fahrenheit"] },
                                },
                                "required": ["location"],
                            },
                        }
                    }
                ],
                tools_choice: {
                    "get_current_weather": {
                        "location": "Boston",
                        "unit": "fahrenheit"
                    }
                }
            });

            const choices = res.choices[0];
            assert.strictEqual('tool_calls', choices.finish_reason);
            assert.deepStrictEqual('get_current_weather', choices.message?.tool_calls?.[0]?.function.name);
        });
    });
});

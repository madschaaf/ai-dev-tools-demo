# Chomsky Client for eBay Internal Cloud

Chomsky Client is a Node.js wrapper around OpenAI's GPT APIs, designed to work seamlessly within eBay's internal cloud ecosystem. This package provides easy-to-use functions to interact with the GPT API, enabling developers to harness the power of generative AI for various applications at eBay.

## Installation

To install the package, run the following command:

```bash
npm install @ebay/chomsky-client
```

## Dependencies 

This module is designed to be used within eBay's Node.js Platform with an application context. If you want to use this stand-alone you have to do add a valid eBay cloud `appName` to the script's context as follows:

```javascript
const AppContext = require('@ebay/app-context-ebay');
AppContext.appName = '<EBAY CLOUD APP NAME>';
```

## Usage

First, require the package in your project:

```javascript
const { openai, MODELS } = require('@ebay/chomsky-client');
```

Since there are no `enum`s in Javascript, `MODELS` is a convenient way to access the models available to you via IDE's code completion features. For example:

```javascript
//EXAMPLES of accessing models for CHAT, TEXT, and EMBEDDING
MODELS.OPENAI.CHAT.AZURE_CHAT_COMPLETIONS_GPT35_TURBO_0301 // "azure-chat-completions-gpt35-turbo-0301"
MODELS.OPENAI.TEXT.AZURE_TEXT_COMPLETIONS_DAVINCI_1 // "azure-text-completions-davinci-1"
MODELS.OPENAI.EMBEDDING.AZURE_EMBEDDINGS_ADA_TEXT_SIMILARITY_2 // "azure-embeddings-ada-text-similarity-2"

// Example usage for a request.
const createCompletionRequest = {
    prompt: `Translate the following English text to French: \"${text}\"`,
    model:  MODELS.OPENAI.TEXT.AZURE_TEXT_COMPLETIONS_GPT35_TURBO_0301,
    max_tokens: 50,
    n: 1,
    stop: null
};
```

If you have a custom model, you can use the model name directly in the request. For example:

```javascript
const createCompletionRequest = {
    prompt: `Translate the following English text to French: \"${text}\"`,
    model:  "custom-model-name",
    max_tokens: 50,
    n: 1,
    stop: null
};
```

For a full list of models in chomsky-client see [lib/models/index.js](https://github.corp.ebay.com/Wonderland/chomsky-client/blob/main/lib/models/index.js). [Wiki](https://wiki.corp.ebay.com/pages/viewpage.action?spaceKey=COREAI&title=Chomsky+Model+Enumeration). [Java Chomsky Gateway Implementation](https://github.corp.ebay.com/KHF/chomskygw/blob/master/src/main/java/com/ebay/app/model/Model.java).

### Create Completion

To create a completion for the provided prompt and parameters, use the `createCompletion` function.

```javascript
const text = "dog";

const createCompletionRequest = {
    prompt: `Translate the following English text to French: \"${text}\"`,
    model:  MODELS.OPENAI.TEXT.AZURE_TEXT_COMPLETIONS_GPT35_TURBO_0301,
    max_tokens: 50,
    n: 1,
    stop: null
};

openai.createCompletion(createCompletionRequest)
    .then(response => {
        console.log(response);
    })
    .catch(error => {
        console.error(error);
    });
```

### Create Embedding

To create an embedding vector representing the input text, use the `createEmbedding` function.

```javascript
const createEmbeddingRequest = {
    input: ['Sample text for embedding'], // Can also be a single string
    model: MODELS.OPENAI.EMBEDDING.AZURE_EMBEDDINGS_ADA_TEXT_SIMILARITY_2
};

openai.createEmbedding(createEmbeddingRequest)
    .then(response => {
        console.log(response);
    })
    .catch(error => {
        console.error(error);
    });
```

### Create Chat Completion 

To create a chat bot, include a `system` message to prime the assistant and pass in array of messages for context of `assistant` or `user` roles, use the `createChatCompletion` function.

```javascript
const createChatCompletionRequest = {
    model: MODELS.OPENAI.CHAT.AZURE_CHAT_COMPLETIONS_GPT35_TURBO_0301,
    messages: [
        {
            "role":"system",
            "content": "You are a complement bot. You are to make people happy."
        },
        {
            "role":"user",
            "content": "I accidentally dropped a production database :("
        }
    ]
};

//Custom headers sent to Chomsky Gateway
const options = {
    headers: {
        'X-CUSTOM-HEADER': 'HEADER_VALUE'
    }
}

openai.createChatCompletion(createChatCompletionRequest, options)
    .then(json => {
        console.log(json.choices[0].message);
        // {
        //     role: 'assistant',
        //     content: "That's okay, everyone makes mistakes. What's important is to learn from them, and I'm sure you'll become even better at handling production databases in the future. Remember, you have the skills and the ability to fix the issue and make it better, and this experience will only make you more knowledgeable and efficient. Keep up the good work!"
        //   }
    });
```

#### Streaming

In order to get streaming response, you need to:

* Use specific model that supports streaming
* Set `stream` as `true` in `createChatCompletionRequest`
* And handle streaming response as SSE stream


The models for streaming are defined [here](https://github.corp.ebay.com/KHF/chomskygw/blob/36a6251655bf04deb67e52f68c6f43e343c0de14/src/main/java/com/ebay/app/model/Model.java#L12-L19):

```java
AZURE_CHAT_COMPLETIONS_GPT35_TURBO_0301("azure-chat-completions-gpt35-turbo-0301"),
AZURE_CHAT_COMPLETIONS_GPT35_TURBO_0301_2023_07_01_PREVIEW("azure-chat-completions-gpt35-turbo-0301-2023-07-01-preview"),
AZURE_CHAT_COMPLETIONS_GPT35_TURBO_0613("azure-chat-completions-gpt35-turbo-0613"),
AZURE_CHAT_COMPLETIONS_GPT35_TURBO_16K_0613("azure-chat-completions-gpt35-turbo-16k-0613"),
AZURE_CHAT_COMPLETIONS_GPT4_0314("azure-chat-completions-gpt4-0314"),
AZURE_CHAT_COMPLETIONS_GPT4_32K_0314("azure-chat-completions-gpt4-32k-0314"),
AZURE_CHAT_COMPLETIONS_GPT4_0613("azure-chat-completions-gpt4-0613"),
AZURE_CHAT_COMPLETIONS_GPT4_32K_0613("azure-chat-completions-gpt4-32k-0613"),
```


```javascript
const createChatCompletionRequest = {
    model: MODELS.OPENAI.CHAT.AZURE_CHAT_COMPLETIONS_GPT35_TURBO_0301,
    messages: [
        {
            "role":"system",
            "content": "You are a complement bot. You are to make people happy."
        },
        {
            "role":"user",
            "content": "I accidentally dropped a production database :("
        }
    ],
    stream: true
};

const response = await openai.createChatCompletion(createChatCompletionRequest, options);

const { createParser } = await import('eventsource-parser');

const chunks = [];
const parser = createParser((event) => {
    if (event.type === 'event') {
        const data = event.data;
        if (data === '[DONE]') {
            return;
        }
        const json = JSON.parse(data);
        chunks.push(json);
    }
});

for await (const chunk of response) {
    parser.feed(String(chunk));
}

const text = chunks.map(chunk => chunk.choices[0].delta.content || '').join('');
```
### Create Dall-E Image

To create an image from a text prompt, use the `createImage` function.

```javascript
    openai.createImage({
        prompt: "a multi-colored umbrella on the beach, disposable camera",
        size: "1024x1024",
        n: 1
    }).then(res => {
        console.log(res.result.contentUrl);
    });
```

## Common Issues/FAQs

### "I'm getting timeouts."

The default timeout value is 5000ms (expect Dall-E which is 1000ms). If you are experiencing timeouts when using the Chomsky Client, you may need to increase the timeout value for your application. To do this, add the following to your application's `config.json` or `<environment>.json` file:

```json
{
    "services": {
        "_openai_embedding": {
            "socketTimeout": x
        },
        "_openai_chat_completion": {
            "socketTimeout": x
        },
        "_openai_completion": {
            "socketTimeout": x
        },    
        "_openai_dalle": {
            "socketTimeout": x
        }  
    }
}
```

Modifying `x` to be the desired timeout value in milliseconds. Depending on the complexity of your request, you may need to increase this value.


### "I'm getting an OpenCircuitError"

This can be triggered by a number of things, but most commonly it is due to a timeout. See the previous section for more information on timeouts.

If that doesn't fix your issue, you're probably hitting the rate limit. Please limit your requests to per second. Contact `DL-eBay-genai-core-grp@ebay.com` with any capacity questions.

### "I am getting the app metadata not found error"

To solve this issue make sure you have registered your application on [Fulcrum](https://go/fulcrum) and have registered the app using [appmeta-register-ebay](https://github.corp.ebay.com/nodejs/appmeta-register-ebay) node module. 

## Getting Ready for Production

Follow the [FOUNDRY](http://go/foundry) process.

## Getting Help

Go in to Slack and go in to `#genai-dev` channel.

## Contributing

If you'd like to contribute to the development of the Node.js Chomsky Client, please feel free to submit pull requests or report any issues you may encounter.

## Upgrading Chomsky Client < version 3.0.0

Note that custom `hostnames` are no longer supported. If you are using a custom hostname, you will need to update your code to use the new `MODELS` enum. Mapping to the appropriate hostname is based on your cloud `appName` and `MODEL` name.

## License

Chomsky Client is released under the [MIT License](https://opensource.org/licenses/MIT).
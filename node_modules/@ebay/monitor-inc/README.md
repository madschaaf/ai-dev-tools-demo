# monitor-inc

[![Build Status](https://go/-/nodejsci/job/nodejs/job/monitor-inc/job/master/badge/icon)](https://go/-/nodejsci/job/nodejs/job/monitor-inc/job/master/) [![Dependency Status](https://nodevalid-i3ey5.vip.lvs01.dev.ebayc3.com/nodejs/monitor-inc.svg)](https://nodevalid-i3ey5.vip.lvs01.dev.ebayc3.com/nodejs/monitor-inc)  [![Code Coverage](https://nodevalid-i3ey5.vip.lvs01.dev.ebayc3.com/coverage/nodejs/monitor-inc)](http://sonar/dashboard/index?id=monitor-inc)


Taniwha are beings that live in deep pools in rivers, dark caves, or in the sea, especially in places with dangerous currents. They are considered protective guardians of people and places. In the spirit of the Kraken and other sea monsters, we have the Maori Taniwha that watches over and protects your application. If we elect to open-source this module, it will likely be as paypal/taniwha.

The `@ebay/monitor-inc` module provides a middleware for monitoring and reporting key application metrics to allow ops/devops/tools to see how an application is performing in LIVE and when it is in trouble. Some of the metrics reported include:
- event loop time
- Number of full garbage collections and frequency of such GCs
- Used heap memory recovery level after a full GC
- Suspected memory leak reporting
- CPU usage
- Request/second and number of concurrent requests handled

## Changelog

See   [CHANGELOG.MD](https://github.corp.ebay.com/nodejs/monitor-inc/blob/master/CHANGELOG.md#changelog)

# Installation
[monitor-inc](https://github.corp.ebay.com/nodejs/brogan-ebay/blob/master/config/config.json#L88) is configured in brogan-ebay by default.

Or the user can install it by run command below:
```
npm install monitor-inc --save
```


# Usage

## Middleware
In order to use the '@ebay/monitor-inc'  module, the following middleware must be enabled:

```javascript
app.use(require('@ebay/monitor-inc').init([options]) );
```

Note that in a Kraken.next app derived from sample-app, this will be automatically enabled by the infrastructure
and options would be configured in config files -- but likely you have nothing you need to configure.

If you have no interest in monitoring request-related metrics, you can just enable the other metrics by doing:

```javascript
require('@ebay/monitor-inc').init([options]);
```

After the above middleware runs, monitoring will be enabled to run periodically and report metrics to Sherlock.
In addition to Sherlock reporting, statistics are emitted as an event you can listen to
and use however you want. To do that:

```javascript
process.on('monitorStats', function(stats) {
    ... do something with stats
});
```

# API

## Configuration

Configuration can be defined by an options param or via a config file.
Configuration options are:
* **pool:** name of the pool (determined automatically but you can override)
* **clientEndPoint:** The end point for receiving Sherlock metrics reporting. It is set automatically
  for production and pre-production. It is defaulted to empty for development to avoid cluttering
  the log with metrics chatter once a minute. For other environments, it goes to the non-production
  end point. You normally will not set this unless you have special needs. If you
  want monitoring in development you should specify the QATE endpoint, `clientEndPoint: "sherlock-ftr-qa.stratus.phx.qa.ebay.com:80"`.
* **tenant:** either mp or pp. This is autodetected so you don't need to supply it.
* **maxLag:** The number of event loop milliseconds that constitutes "too busy" and results in a call
  to the tooBusyHandler.
* **tooBusyHandler:** If maxLag is exceeded, the applications "tooBusyHandler" will be given control
  to deal with the situation. A common response is to return a 503 response page.
  If you don't want any tooBusy handling, just don't specify a handler.
  If a value is specified, a `require(tooBusyHandler)` will be done to obtain the function to call.
  The function will be called with parameters (request, response, next) just like a route receives.
* **maxOpenRequests:** maximum number of received but not completed requests. If the number
  in process exceeds this amount, an HTTP 503 response will be returned. This is a
  way to prevent unbounded demands on the app when it may be blocked by services that
  are down. If back pressure is not exerted, new requests continue to be accepted and
  added to the event loop using more and more memory. Ideally, the app itself will
  deal with marked down or timed out services in a more graceful way so this is just
  a backup protection. Set it to a number you never expect your app to support in
  one processor at one time. Default is 0 which means no limit.

Sample configuration options:

```
{
    "reportSystemCPU": true // << tell to report overall CPU (all cores)
}
```

`maxLag` would typically not be configured but is shown here. This is the
amount of time to go around the NodeJs event loop. If it exceeds the default 70 msec.
your app is probably in trouble and needs to exert backpressure on the user.
If you need some other value, you can configure it (but not lower than 10).
If configured, the tooBusyHandler will be called to generate a response to the user.

`clientGroup` is used to connect similar logged data from multiple instances
of the application and to support authorization to send metrics and quota.
This is determined for your application.

The `clientEndPoint` will be provided by the infrastructure but if you need
to override it, you can.

If the application heap usage exceeds 1.2GB, the application will be killed
and there is a presumption that forever, pm2 or some other app manager will
restart it. If the environment variable `NODE_HEAPDUMP_OPTIONS=dump` is set,
a full heapdump will be written to the logs directory. It is not written
by default out of concern for putting PII data on disk.

If a restart of the application is detected, an email will
be sent to a monitoring DL plus any other DL configured in config/config.json.
The mails are sent in production and pre-production. If you add a `stageToAddr`
to the config, you can force mails to be sent for crashes on stage machines.
Note that stageToAddr overrides whatever is in monitor:toAddr. The
`toAddr` and `stageToAddr` values can be a comma-separated list of
email addresses.

```
"monitor": {
    "toAddr": "DL-xxxxx@corp.ebay.com"
    "stageToAddr": "DL-xxxxx@corp.ebay.com"
}
```

# Additional Information

## Reported metrics

Memory related

- `gc_count` number of full garbage collects
- `gc_count_incremental number of incremental garbage collects
- `heapSizePostGC`
- `gcInterval` percent of total CPU spent doing GC
- `rss` (memory used for compiled js/jit code)
- `heapUsed`
- `heapTotal`
- `memoryLeakReports` (count of instances of Out-of-Memory restarts)

CPU/session/app related

- `cpu` (% CPU used, it can report overall CPU usage or just for single nodejs process (default))
- `uptime`
- `eventLoop` (msec to go around event loop)
- `availableFileDescriptors`
- `noWorkers`
- `restarts` (# of times your app has restarted)

Request Processing related

- `urlTime`
- `renderTime`
- `concurrentRequests`
- `cookieSizeMax`
- `requestBodySize`
- `sessionSize`
- `tps` (transactions/second aka requests/second)
- `eps` (errors/second)
- `http2xx` (Number of 200 responses)
- `http3xx` (Number of 300 responses)
- `http4xx` (Number of 400 responses)
- `http5xx` (Number of 500 responses)

## TSDB monitoring
A basic tool for viewing your monitoring data, TSDB, is available for
the various endpoints your app might report to. Those can be
determined from here as the Query Service Endpoints.

https://wiki.vip.corp.ebay.com/display/appmonitring/Sherlock+Frontier

The TSDB we run is based on an open-source product. The documentation
will help you to use the tool but our version is a bit older than
what is documented so minor differences may exist.

http://opentsdb.net/docs/build/html/index.html

## Custom Dashboard
Sherlock provides a mechanism for you to define a custom dashboard and see
graphs of various metrics: http://sherlock.vip.ebay.com/MySherlockApp/MyDashboards

You can click the big blue "Create Dashboard" button to get started.

The next screen provides a series of settings you need to work throgh:
* First choose Marketplaces or PayPal depending on where your app runs
* Then click on the "Profile" drop-down and start typing nodejs_perfmon. Before you get far, it will be the only choice so click the radio button to select it.
* Then click on the "Metric" drop-down and select one of the above metrics -- just start typing the name until it is the only one visible and then check the radio button. e.g., type "cpu" and you can check nodejs_perfmon.cpu
* Then click on the "Dimensions" drop-down and select the granularity of what you want to graph. "pool" is likely to be the most common but some may which to graph by colo or host.
* If you choose pool, then the "Dimension Value(s) drop-down should show your pool name (assuming your app has been emitting data already). You cannot preconfigure a dashboard until your app has begun sending data. Check the "Dimension Value(s) you are interested in.
* If you click the "Add  Graph To" button and choose "Default Graph", the single set of dimension data will be added to the dashboard as a graph. If you want to plot more than one dimension of data on the same graph, click the big "+" at the right end  of the dimension defintion dropdowns line, and you can define more dimensions. When you have all you want,use "Add Graph To" in order to create the graph.
* When you are done defining graphs, use the "Save Dashboard" at the bottom right to save all your work and create the  Custom Dashboard. A popup dialogs lets you name the dashboard and control the degree of sharing. There are other things you can do but I defer to the Sherlock team documentation for those.

## Metrics Details

For those wanting more insight into exactly how each metric is computed

```
 name: 'eventLoop', // time for a circuit of the node event loop
 'GAUGE', Integer, units: 'msec.'
 name: 'gc_count', // # of full garbace collects in this interval
 'GAUGE', Integer
 name: 'gc_count_incremental', // # of incremental garbage collects in this interval
 'GAUGE', Integer
 name: 'heapSizePostGC' // Heap size after a full GC
 'GAUGE', Integer, units: 'Kbytes'
 name: 'heap_max' // Maximum heap size. Note node periodically bumps this up
 'GAUGE', Integer, units: 'Kbytes'
 name: 'heap_used' // amount of heap currently used
 'GAUGE', Integer, units: 'Kbytes'
 name: 'rss'  // V8's memory usage
 'GAUGE', Integer, units: 'Kbytes'
 name: 'gcInterval'  // % of cp time spent doing GC in the interval
 'GAUGE', Float
 name: 'memoryLeakReports'  // Number of out-of-memory events since last deploy
 'COUNTER', Integer
 name: 'uptime'  // uptime value reported by node's process.uptime
 'COUNTER', Integer, units: 'sec'
 name: 'concurrentRequests' // Maximum # of requests in process at once in last 60 seconds
 'GAUGE', Integer
 name: 'urlTime' // median url time in last 60 seconds
 'GAUGE', Float, units: 'msec'
 name: 'fd_available' // # of available file descriptors at end of each 60 second reporting interval
 'GAUGE', Integer
 name: 'renderTime' // Median render time in last 60 seconds
 'GAUGE', Float, units: 'msec'
 name: 'eps'  // # 4xx/5xx responses/60 seconds
 'GAUGE', Float
 name: '2XXCount'  // Count of 5xx responses in last 60 seconds
 'COUNTER', Integer
 name: '3XXCount'  // Count of 5xx responses in last 60 seconds
 'COUNTER', Integer
 name: '4XXCount'  // Count of 4xx responses in last 60 seconds
 'COUNTER', Integer
 name: '5XXCount' // Count of 5xx responses in last 60 seconds
 'COUNTER', Integer
 name: 'RequestBodySize' // Median size seen in last 60 seconds
 'GAUGE', Float, units: 'bytes'
 name: 'MaxCookieSize' // Max size seen each 60 seconds
 'GAUGE', Integer, units: 'bytes'
 name: 'sessionSize'
 'GAUGE', Integer, units: 'bytes'
 name: 'tps' // Transactions/second # transactions/60 seconds
 'GAUGE', Float
 name: 'cpu' // Percent CPU usage
 'GAUGE', Float, units: 'percentage'
 name: 'noWorkers' // Number of node instances running
 'GAUGE', Integer
 name: 'restarts' // Number of restarts since last deploy
 'GAUGE', Integer
```
